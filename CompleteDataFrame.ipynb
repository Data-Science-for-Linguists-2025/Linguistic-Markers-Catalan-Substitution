{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "059448c8-5573-4188-9344-2b9c72caa1e0",
   "metadata": {},
   "source": [
    "### 2.5 Complete dataframe with FULL RADIOTECA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222c496-c93b-4baf-8b46-50b87d6b46f1",
   "metadata": {},
   "source": [
    "Some of the data frames come with a great amount of metadata that won't be necessary for our research purposes. To keep it we will maintain the separate dataframes and create a merged one extracting only the columns necessary for our research question. That will be the title, date and text/content. We will also create other columns that will be useful for our Exploratory Data Analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec59667-f472-4199-92d6-0c83edf7fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb14518-2b44-482c-bc5e-398e4bfd028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the individual dataframes from their pickled form\n",
    "CTILC_df = pd.read_pickle(\"Data/CTILC.pkl\")\n",
    "parlament_parla_df = pd.read_pickle(\"Data/parlaparla.pkl\")\n",
    "parlaMint_df = pd.read_pickle(\"Data/parlaMint.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54372918-c0cb-48ce-b29a-f1cb7ee0833b",
   "metadata": {},
   "source": [
    "**Comment:** We will treat radioteca differently by loading the data in chuncks instead of all at once as it would make the notebook crash. Moreover, as this notebook and process was re-done after scraping the enirety of radioteca df, we already know it will give us a very imbalenced distribution of the data. It is a massive dataframe but it will only bring in lots of data about the same years, which is not what we are looking for. Therefore, we will perform 2 strategies to reduce the amount of data and create a sample of the whole radioteca dataframe while trying to avoid any biases. \n",
    "\n",
    "The strategies, as in the original notebook, will be:\\\n",
    "**Strategy 1:Limiting Individual Contribution**\\\n",
    "Aiming for the most unbiased and representative data, we will first drop individual Speaker's contributions if they are over 1500 characters (about 200 words) long for the Radioteca data. This will allow for a less speaker-specific analysis.\\\n",
    "**Strategy 2: Balancing Program  Contribution**\\\n",
    "Since Radioteca has a lot of metadata, we will also use another piece of data ensure a more representative distribution while reducing the data size by limiting a show's episode contribution to 1500 characters as well. That way, we are also ensuring a more diverse corpora topic-wise and less show-specific data.\n",
    "\n",
    "We will do it without loading the full dataset completely, year file per year file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66db7d4b-2216-4b0e-957d-e488f9b70782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for strategy 1, speaker limit (we will reuse it for the other larger dataframes\n",
    "def under1500(dataframe, contrivutorColName):\n",
    "    '''\n",
    "    takes in a dataframe\n",
    "    after the cumulative text length of one speaker goes over 1500 characters\n",
    "    the following contributions are no longer added to the dataframe\n",
    "    ensuring a max of 1500 characters per speaker/contributor\n",
    "    prints out the maximum and minimum length per contributor before and after the change\n",
    "    '''\n",
    "    if contrivutorColName == \"Speaker\":\n",
    "        dataframe[\"CUMSUM_len\"] = dataframe.groupby([\"Episode\", contrivutorColName])[\"Text_len\"].cumsum()\n",
    "    else:\n",
    "        dataframe[\"CUMSUM_len\"] = dataframe.groupby(contrivutorColName)[\"Text_len\"].cumsum()\n",
    "    max1500_df = dataframe[dataframe[\"CUMSUM_len\"] <= 1500]\n",
    "    if contrivutorColName == \"Speaker\":\n",
    "        before_spkcount = dataframe.groupby([\"Episode\", contrivutorColName])[\"Text_len\"].sum()\n",
    "        after_spkcount = max1500_df.groupby([\"Episode\", contrivutorColName])[\"Text_len\"].sum()\n",
    "    else:\n",
    "        before_spkcount = dataframe.groupby(contrivutorColName)[\"Text_len\"].sum()\n",
    "        after_spkcount = max1500_df.groupby(contrivutorColName)[\"Text_len\"].sum()\n",
    "\n",
    "    #printing contribution max and min to ensure the process worked out well\n",
    "    print()\n",
    "    print(\"Before speaker contribution limit:\")\n",
    "    print(\"The character count for the speaker contrbuting with the most amount of data is\", before_spkcount.max())\n",
    "    print(\"The character count for the speaker contrbuting with the least amount of data is\", before_spkcount.min())\n",
    "    print(\"After speaker contribution limit:\")\n",
    "    print(\"The character count for the speaker contrbuting with the most amount of data is\", after_spkcount.max())\n",
    "    print(\"The character count for the speaker contrbuting with the least amount of data is\", after_spkcount.min())\n",
    "\n",
    "    return max1500_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e54aac0-5eba-4c51-9c63-f57e4f69ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as glob\n",
    "\n",
    "for f in glob.glob(\"Data/radioteca_year_*.parquet\"):\n",
    "    radioteca_Ydf = pd.read_parquet(f)\n",
    "\n",
    "    # Strategy 1: limit speaker contributions to 1500 characters\n",
    "    radioteca_Ydf = under1500(radioteca_Ydf, \"Speaker\")\n",
    "\n",
    "    # Apply Strategy 2: limit episode contributions\n",
    "    radioteca_Ydf[\"CUMSUM_ep\"] = radioteca_Ydf.groupby(\"Episode\")[\"Text_len\"].cumsum()\n",
    "    radioteca_Ydf = radioteca_Ydf[radioteca_Ydf[\"CUMSUM_ep\"] <= 1500]\n",
    "\n",
    "    radioteca_Ydf.to_parquet(f\"radioteca_year_{year}_reduced.parquet\")\n",
    "    print(f\"radioteca_year_{year}_reduced.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feba52ff-495c-4599-b924-432b2ee1e09a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/full_radioteca_cleaned.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parquet.py:274\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    268\u001b[0m     path,\n\u001b[1;32m    269\u001b[0m     filesystem,\n\u001b[1;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyarrow/parquet/core.py:1793\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification)\u001b[0m\n\u001b[1;32m   1787\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1788\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated as of pyarrow 15.0.0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1789\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand will be removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1790\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1793\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mParquetDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1802\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1803\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecryption_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecryption_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1808\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpage_checksum_verification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1809\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[1;32m   1813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyarrow/parquet/core.py:1360\u001b[0m, in \u001b[0;36mParquetDataset.__init__\u001b[0;34m(self, path_or_paths, filesystem, schema, filters, read_dictionary, memory_map, buffer_size, partitioning, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, page_checksum_verification, use_legacy_dataset)\u001b[0m\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1357\u001b[0m     fragment \u001b[38;5;241m=\u001b[39m parquet_format\u001b[38;5;241m.\u001b[39mmake_fragment(single_file, filesystem)\n\u001b[1;32m   1359\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mFileSystemDataset(\n\u001b[0;32m-> 1360\u001b[0m         [fragment], schema\u001b[38;5;241m=\u001b[39mschema \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mfragment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphysical_schema\u001b[49m,\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mparquet_format,\n\u001b[1;32m   1362\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfragment\u001b[38;5;241m.\u001b[39mfilesystem\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;66;03m# check partitioning to enable dictionary encoding\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyarrow/_dataset.pyx:1443\u001b[0m, in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(\"data/full_radioteca_cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "675aa485-f7d7-4675-b077-840256f86082",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'radioteca_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m reduced_parlament_parla \u001b[38;5;241m=\u001b[39m parlament_parla_df\u001b[38;5;241m.\u001b[39mfilter([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentence\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText_len\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m reduced_parlamint \u001b[38;5;241m=\u001b[39m parlaMint_df\u001b[38;5;241m.\u001b[39mfilter([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText_len\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m reduced_radioteca \u001b[38;5;241m=\u001b[39m \u001b[43mradioteca_df\u001b[49m\u001b[38;5;241m.\u001b[39mfilter([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLine_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText_len\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'radioteca_df' is not defined"
     ]
    }
   ],
   "source": [
    "# creating a reduced dataframe with only the date info, title of the file, content/text columns and its length\n",
    "reduced_CTILC = CTILC_df.filter([\"Year\", \"Title\", \"Text\", \"Text_len\"])\n",
    "reduced_parlament_parla = parlament_parla_df.filter([\"Path\", \"Sentence\", \"Text\", \"Text_len\"])\n",
    "reduced_parlamint = parlaMint_df.filter([\"Date\", \"Title\", \"Text\", \"Text_len\"])\n",
    "reduced_radioteca = radioteca_df.filter([\"Year\", \"Line_id\", \"Text\", \"Text_len\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e407b63a-60cb-44db-9011-07622ebaa730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a Source Corpora column to keep the data\n",
    "reduced_CTILC[\"Source_corpora\"] = \"CTILC\"\n",
    "reduced_parlament_parla[\"Source_corpora\"] = \"Parlament Parla\"\n",
    "reduced_parlamint[\"Source_corpora\"] = \"ParlaMint\"\n",
    "reduced_radioteca[\"Source_corpora\"] = \"Radioteca.cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c97f0a-e0f4-4232-8c50-78767bcb116c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_len</th>\n",
       "      <th>Source_corpora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clean_train/3/1/31ca4d158eaef166c37a_18.87_23....</td>\n",
       "      <td>perquè que el president de catalunya sigui reb...</td>\n",
       "      <td>85</td>\n",
       "      <td>Parlament Parla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clean_train/3/1/31ca4d158eaef166c37a_60.13_65....</td>\n",
       "      <td>que lliga absolutament amb allò que vostè diu ...</td>\n",
       "      <td>115</td>\n",
       "      <td>Parlament Parla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clean_train/2/8/2803008bb00cb0c86de6_17.0_30.1...</td>\n",
       "      <td>gràcies presidenta consellera atès l'inici del...</td>\n",
       "      <td>176</td>\n",
       "      <td>Parlament Parla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clean_train/2/8/2803008bb00cb0c86de6_31.03_44....</td>\n",
       "      <td>li volem preguntar si el seu departament té pr...</td>\n",
       "      <td>209</td>\n",
       "      <td>Parlament Parla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clean_train/2/8/2803008bb00cb0c86de6_44.74_53....</td>\n",
       "      <td>per tal d'iniciar la recuperació de l'ensenyam...</td>\n",
       "      <td>160</td>\n",
       "      <td>Parlament Parla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  \\\n",
       "0  clean_train/3/1/31ca4d158eaef166c37a_18.87_23....   \n",
       "1  clean_train/3/1/31ca4d158eaef166c37a_60.13_65....   \n",
       "2  clean_train/2/8/2803008bb00cb0c86de6_17.0_30.1...   \n",
       "3  clean_train/2/8/2803008bb00cb0c86de6_31.03_44....   \n",
       "4  clean_train/2/8/2803008bb00cb0c86de6_44.74_53....   \n",
       "\n",
       "                                                Text  Text_len  \\\n",
       "0  perquè que el president de catalunya sigui reb...        85   \n",
       "1  que lliga absolutament amb allò que vostè diu ...       115   \n",
       "2  gràcies presidenta consellera atès l'inici del...       176   \n",
       "3  li volem preguntar si el seu departament té pr...       209   \n",
       "4  per tal d'iniciar la recuperació de l'ensenyam...       160   \n",
       "\n",
       "    Source_corpora  \n",
       "0  Parlament Parla  \n",
       "1  Parlament Parla  \n",
       "2  Parlament Parla  \n",
       "3  Parlament Parla  \n",
       "4  Parlament Parla  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_parlament_parla.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff30674-e144-4a25-af13-02d57530ba81",
   "metadata": {},
   "source": [
    "There is no date metadata provided for the parlament parla dataframe.\\\n",
    "For our purposes, as we need a date we will make an aproximation based off the data given by the owners.\\\n",
    "As Parlament Parla is presented as a corpora containing data from 2007 to 2015 we will assign the date aproximation 2010 to all the data in the Parlament Parla dataframe.\\\n",
    "We will also only keep the year infomation as the date in the corpora parlamint and the radioteca data frame where the full (month, day, year) information was provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31dc35d6-a7dd-43d3-9211-77d29031fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 2010 date to parlament parla rows\n",
    "reduced_parlament_parla[\"Year\"] = 2010\n",
    "\n",
    "# keeping only the year on parlaMint\n",
    "reduced_parlamint[\"Date\"] = reduced_parlamint[\"Date\"].apply(lambda x :x[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f19357-086e-4648-ab98-c78cc9541651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_len</th>\n",
       "      <th>Source_corpora</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clean_train/3/1/31ca4d158eaef166c37a_18.87_23....</td>\n",
       "      <td>perquè que el president de catalunya sigui reb...</td>\n",
       "      <td>85</td>\n",
       "      <td>Parlament Parla</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clean_train/3/1/31ca4d158eaef166c37a_60.13_65....</td>\n",
       "      <td>que lliga absolutament amb allò que vostè diu ...</td>\n",
       "      <td>115</td>\n",
       "      <td>Parlament Parla</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path  \\\n",
       "0  clean_train/3/1/31ca4d158eaef166c37a_18.87_23....   \n",
       "1  clean_train/3/1/31ca4d158eaef166c37a_60.13_65....   \n",
       "\n",
       "                                                Text  Text_len  \\\n",
       "0  perquè que el president de catalunya sigui reb...        85   \n",
       "1  que lliga absolutament amb allò que vostè diu ...       115   \n",
       "\n",
       "    Source_corpora  Year  \n",
       "0  Parlament Parla  2010  \n",
       "1  Parlament Parla  2010  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_parlament_parla.head(2) # checking if we successfully created the Year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33f6225a-8f2c-493b-9966-a203a7276b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "# casting year as integer\n",
    "print(type(reduced_radioteca[\"Year\"][0])) # it is currently a float that we extracted from the complete date\n",
    "reduced_radioteca[\"Year\"] = reduced_radioteca[\"Year\"].apply(int)\n",
    "print(type(reduced_radioteca[\"Year\"][0])) # checking if data type is now what we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd47169-451f-4c99-a36f-76a9de106862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting column names to match before concatenating\n",
    "reduced_CTILC = reduced_CTILC.rename(columns ={\"Year\":\"Year\", \"Title\":\"Line_id\", \"Text\":\"Text\", \n",
    "                                                                   \"Source_corpora\":\"Source_corpora\", \"Text_len\":\"Text_len\"})\n",
    "reduced_parlament_parla = reduced_parlament_parla.rename(columns ={\"Year\":\"Year\", \"Path\":\"Line_id\", \"Text\":\"Text\", \n",
    "                                                                   \"Source_corpora\":\"Source_corpora\", \"Text_len\":\"Text_len\"})\n",
    "reduced_parlamint = reduced_parlamint.rename(columns ={\"Date\":\"Year\", \"Title\":\"Line_id\", \"Text\":\"Text\", \n",
    "                                                       \"Source_corpora\":\"Source_corpora\", \"Text_len\":\"Text_len\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c50e2b79-95c2-4eff-9d05-a0ebc833c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all datasets' relevant columns in a single data frame\n",
    "complete_data = pd.concat([reduced_CTILC, reduced_parlament_parla, reduced_parlamint, reduced_radioteca]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c830de0d-b8fe-4326-a273-0e942831c354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Line_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_len</th>\n",
       "      <th>Source_corpora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1926</td>\n",
       "      <td>Discurs llegit per... donar a conèxer la perso...</td>\n",
       "      <td>L'home que per amor al estudi, impulsat per un...</td>\n",
       "      <td>37497.0</td>\n",
       "      <td>CTILC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1920</td>\n",
       "      <td>Parlament llegit en la festa inaugural de l'Or...</td>\n",
       "      <td>Cantaires de la Garriga, Senyores i senyors:\\n...</td>\n",
       "      <td>9253.0</td>\n",
       "      <td>CTILC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900</td>\n",
       "      <td>Discurs-pròlec</td>\n",
       "      <td>Discurs-prolec Llegit en la societat mèdic-far...</td>\n",
       "      <td>73881.0</td>\n",
       "      <td>CTILC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1894</td>\n",
       "      <td>Discurs</td>\n",
       "      <td>Senyors excelentissims, senyors:\\n\\nQuan rebí ...</td>\n",
       "      <td>29393.0</td>\n",
       "      <td>CTILC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1903</td>\n",
       "      <td>Discurs</td>\n",
       "      <td>Senyors:\\n\\nSembla que era air, y fa ja uns qu...</td>\n",
       "      <td>26577.0</td>\n",
       "      <td>CTILC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                                            Line_id  \\\n",
       "0  1926  Discurs llegit per... donar a conèxer la perso...   \n",
       "1  1920  Parlament llegit en la festa inaugural de l'Or...   \n",
       "2  1900                                     Discurs-pròlec   \n",
       "3  1894                                            Discurs   \n",
       "4  1903                                            Discurs   \n",
       "\n",
       "                                                Text  Text_len Source_corpora  \n",
       "0  L'home que per amor al estudi, impulsat per un...   37497.0          CTILC  \n",
       "1  Cantaires de la Garriga, Senyores i senyors:\\n...    9253.0          CTILC  \n",
       "2  Discurs-prolec Llegit en la societat mèdic-far...   73881.0          CTILC  \n",
       "3  Senyors excelentissims, senyors:\\n\\nQuan rebí ...   29393.0          CTILC  \n",
       "4  Senyors:\\n\\nSembla que era air, y fa ja uns qu...   26577.0          CTILC  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a376325-e9eb-4b07-b297-38fb100ef36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                     0\n",
      "Line_id                  0\n",
      "Text                     0\n",
      "Text_len          29700188\n",
      "Source_corpora           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(complete_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2551527-d191-437b-bb7c-6c2293ff6610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Line_id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_len</th>\n",
       "      <th>Source_corpora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1860</td>\n",
       "      <td>Discurs</td>\n",
       "      <td>Breu seré, cuant ja se han complagut vostres o...</td>\n",
       "      <td>9551.0</td>\n",
       "      <td>CTILC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1868</td>\n",
       "      <td>Discurs</td>\n",
       "      <td>Excel·lentissim senyor:\\n\\nA últims del segle ...</td>\n",
       "      <td>18618.0</td>\n",
       "      <td>CTILC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1873</td>\n",
       "      <td>Discurs pronunciat en la sessió inaugural que ...</td>\n",
       "      <td>Senyors:\\n\\nDever meu es avuy 'l dirigirvos la...</td>\n",
       "      <td>36899.0</td>\n",
       "      <td>CTILC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1876</td>\n",
       "      <td>Teatre catalá</td>\n",
       "      <td>Sempre es estada tal la seua manera de reprodu...</td>\n",
       "      <td>62307.0</td>\n",
       "      <td>CTILC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1878</td>\n",
       "      <td>Discurs inaugural</td>\n",
       "      <td>Discurs inaugural.\\n\\nExcel·lentísim senyor; S...</td>\n",
       "      <td>21840.0</td>\n",
       "      <td>CTILC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445207</th>\n",
       "      <td>2025</td>\n",
       "      <td>Veu A00:40:27</td>\n",
       "      <td>Encara vinculat a les drogues, atenció a aques...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radioteca.cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445206</th>\n",
       "      <td>2025</td>\n",
       "      <td>Veu C00:40:06</td>\n",
       "      <td>Aquests nous opioides es diuen nitasens, són u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radioteca.cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445205</th>\n",
       "      <td>2025</td>\n",
       "      <td>Veu A00:38:49</td>\n",
       "      <td>I atenció a la notícia que s'ha publicat a les...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radioteca.cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445213</th>\n",
       "      <td>2025</td>\n",
       "      <td>Veu A00:42:41</td>\n",
       "      <td>I a Barcelona, la Guàrdia Urbana investiga tam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radioteca.cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579863</th>\n",
       "      <td>2025</td>\n",
       "      <td>Veu F00:42:41</td>\n",
       "      <td>El govern de coalició amb David Cameron.\\nHi h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Radioteca.cat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29831818 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year                                            Line_id  \\\n",
       "27      1860                                            Discurs   \n",
       "23      1868                                            Discurs   \n",
       "26      1873  Discurs pronunciat en la sessió inaugural que ...   \n",
       "25      1876                                      Teatre catalá   \n",
       "21      1878                                  Discurs inaugural   \n",
       "...      ...                                                ...   \n",
       "445207  2025                                      Veu A00:40:27   \n",
       "445206  2025                                      Veu C00:40:06   \n",
       "445205  2025                                      Veu A00:38:49   \n",
       "445213  2025                                      Veu A00:42:41   \n",
       "579863  2025                                      Veu F00:42:41   \n",
       "\n",
       "                                                     Text  Text_len  \\\n",
       "27      Breu seré, cuant ja se han complagut vostres o...    9551.0   \n",
       "23      Excel·lentissim senyor:\\n\\nA últims del segle ...   18618.0   \n",
       "26      Senyors:\\n\\nDever meu es avuy 'l dirigirvos la...   36899.0   \n",
       "25      Sempre es estada tal la seua manera de reprodu...   62307.0   \n",
       "21      Discurs inaugural.\\n\\nExcel·lentísim senyor; S...   21840.0   \n",
       "...                                                   ...       ...   \n",
       "445207  Encara vinculat a les drogues, atenció a aques...       NaN   \n",
       "445206  Aquests nous opioides es diuen nitasens, són u...       NaN   \n",
       "445205  I atenció a la notícia que s'ha publicat a les...       NaN   \n",
       "445213  I a Barcelona, la Guàrdia Urbana investiga tam...       NaN   \n",
       "579863  El govern de coalició amb David Cameron.\\nHi h...       NaN   \n",
       "\n",
       "       Source_corpora  \n",
       "27              CTILC  \n",
       "23              CTILC  \n",
       "26              CTILC  \n",
       "25              CTILC  \n",
       "21              CTILC  \n",
       "...               ...  \n",
       "445207  Radioteca.cat  \n",
       "445206  Radioteca.cat  \n",
       "445205  Radioteca.cat  \n",
       "445213  Radioteca.cat  \n",
       "579863  Radioteca.cat  \n",
       "\n",
       "[29831818 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting joined data by year, from oldest to most recent\n",
    "complete_data[\"Year\"] = complete_data[\"Year\"].apply(lambda x : int(x)) # casting all Years as integers, as we have some strings mixed up\n",
    "complete_data.sort_values([\"Year\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41e20409-d863-4525-a6c4-dfe3e05458fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index after sorting\n",
    "complete_data = complete_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2419ed22-7288-4052-bcd9-17e3f54c0c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling the complete joined data frame\n",
    "complete_data.to_pickle(\"myfulldata.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8431cf-9875-4148-a453-36520a2820e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dictionary of the cumulative amount of characters per year\n",
    "year_length = {}\n",
    "# setting year as the index of the dataframe\n",
    "complete_data = complete_data.set_index(\"Year\")\n",
    "# iterating over the rows \n",
    "for year, row in complete_data.iterrows():\n",
    "    if year not in year_length:\n",
    "        year_length[year] = row[\"Text_len\"]  # initializing year's length total\n",
    "    else:\n",
    "        year_length[year] += row[\"Text_len\"]  # accumulating length to already present year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee90bb-9f2f-462d-905d-19b5da741fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_length = dict(sorted(year_length.items(), key=lambda item: item[1]))\n",
    "for key in year_length.keys():\n",
    "    value = year_length[key]\n",
    "    #print(key, \"-\", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786c7f6-4ff0-4656-8a74-92c774c05e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker  \n",
    "\n",
    "# placeholder y-values for timeline\n",
    "years = list(year_length.keys())  \n",
    "y_values = np.ones(len(years)) \n",
    "\n",
    "# creating mosaic layout for our multiple plots\n",
    "fig, ax = plt.subplot_mosaic([[\"B\", \"B\"],  # Timeline\n",
    "                              [\"A\", \"A\"],  # Histogram\n",
    "                              [\"D\", \"D\"]],  # Text count & corpus length\n",
    "                             figsize=(10, 8),\n",
    "                             constrained_layout=True)\n",
    "\n",
    "# (A) Histogram of Document Distribution Over Time\n",
    "ax[\"A\"].hist(complete_data.index, bins=min(20, len(years)), histtype=\"step\", color=\"blue\", lw=1.5)\n",
    "ax[\"A\"].ticklabel_format(style='plain', axis='y')\n",
    "ax[\"A\"].set_title(\"Document Distribution Over Time\")\n",
    "ax[\"A\"].set_xlabel(\"Year\")\n",
    "ax[\"A\"].set_ylabel(\"Count\")\n",
    "\n",
    "# (B) Timeline (Scatter Plot)\n",
    "ax[\"B\"].scatter(years, y_values, color=\"blue\", marker=\"o\", lw=1.5)\n",
    "ax[\"B\"].set_title(\"Timeline of Documents\")\n",
    "ax[\"B\"].set_xlabel(\"Year\")\n",
    "ax[\"B\"].set_yticks([])  # Remove y-axis labels since they are not meaningful\n",
    "ax[\"B\"].grid(axis=\"x\")\n",
    "\n",
    "# (D) Text length per year in character counts\n",
    "capped_values = [min(val, 10_000_000) for val in year_length.values()]  # limit to 10M\n",
    "\n",
    "ax[\"D\"].barh(list(year_length.keys()), capped_values, color=\"blue\")\n",
    "ax[\"D\"].set_title(\"Text Length per Year (capped after 10M)\")  \n",
    "ax[\"D\"].set_xlabel(\"Text Length\")  \n",
    "\n",
    "# Fix Tick Labels (Without `ticker`)\n",
    "x_ticks = ax[\"D\"].get_xticks()  \n",
    "ax[\"D\"].set_xticks(x_ticks)  \n",
    "ax[\"D\"].set_xticklabels([f\"{int(x):,}\" for x in x_ticks])  \n",
    "ax[\"D\"].set_xlim(0, 10_000_000)\n",
    "\n",
    "# displaying the plots' mosaic\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
